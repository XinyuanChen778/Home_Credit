---
title: "EDA"
author: "Xinyuan Chen"
date: "2025-02-16"
output: 
  html_document:
    theme: simplex
    code_folding: 
    toc: yes
    toc_float:
      collapsed: true
---
# Introduction

## Business Problem
Home Credit Group provides financial services to people who may not have a traditional credit history, making it difficult to determine whether they can repay a loan. Without standard credit data, lenders risk making the wrong decisions—either approving loans for people who might default or rejecting creditworthy applicants who could have successfully repaid. The goal of this project is to build a predictive model that helps predict an applicants' ability to repay, allowing for smarter and fairer lending decisions.

## Analytic Problems
To make accurate predictions, we need to analyze multiple datasets, including information about current loan applications, past loans with Home Credit, and external credit history from other financial institutions. These datasets contain valuable insights into applicants’ financial behavior, such as how they have managed previous loans, their payment patterns, and their overall credit utilization. The challenge is to clean and combine this data, handle missing values, and extract meaningful patterns that will help the model make better lending decisions.

## Questions and Purpose
Before building the model, it is necessary to explore the data to understand its structure and key trends. This includes checking for missing values, analyzing applicant financial behavior, and identifying which factors influence loan repayment.

Key Questions:

- **How do income and credit amount affect loan repayment?**  
- **What patterns exist in past loan approvals and defaults?**  
- **How does an applicant’s credit history impact repayment?**  
- **Are there correlations between key financial indicators?**  

The ultimate purpose of this EDA notebook is to refine the data and build a more effective model that improves loan approvals while reducing financial risk.

# Description of the Data

## Data Import
```{r message=FALSE, warning=FALSE}
# Load Library
library(readr)
library(dplyr) 
library(ggplot2)
library(skimr)
library(corrplot)
library(VIM) 
library(knitr)
library(DT) 
library(corrr)
library(reshape2)
library(tidyverse)
library(data.table)
library(caret)

setwd("/Users/chenxinyuan/Documents/Project Practice - Capstone/Home Credit/Home_Credit")
```

```{r message=FALSE, warning=FALSE}
train <- read_csv("application_train.csv")
test <- read_csv("application_test.csv")
bureau <- read_csv("bureau.csv")
bureau_balance <- read_csv("bureau_balance.csv")
previous_application <- read_csv("previous_application.csv")
POS_CASH_balance <- read_csv("POS_CASH_balance.csv")
installments_payments <- read_csv("installments_payments.csv")
credit_card_balance <- read_csv("credit_card_balance.csv")
```

## Explor Data Size
```{r message=FALSE, warning=FALSE}
sizes <- data.frame(
  Dataset = c("train", "bureau", "bureau_balance", 
              "previous_application", "POS_CASH_balance", 
              "installments_payments", "credit_card_balance","test"),
  Rows = c(nrow(train), nrow(bureau), nrow(bureau_balance), 
           nrow(previous_application), nrow(POS_CASH_balance), 
           nrow(installments_payments), nrow(credit_card_balance),nrow(test)),
  Columns = c(ncol(train), ncol(bureau), ncol(bureau_balance), 
              ncol(previous_application), ncol(POS_CASH_balance), 
              ncol(installments_payments), ncol(credit_card_balance),ncol(test))
)
print(sizes)
```
The dataset has several tables, with `train` (307K rows, 122 columns) as the main file containing loan details and repayment status. The largest dataset is `bureau_balance` (27.3M rows), which tracks past credit history, making it complex to handle.

Key datasets for predicting loan repayment include `train|test`, `bureau`, `previous_application`, `installments_payments`, and `credit_card_balance`, as they contain financial and payment behavior. Challenges include handling large datasets, merging multiple tables, dealing with missing values, and extracting useful features for better predictions.

## Number of Unqiue Values
```{r message=FALSE, warning=FALSE}
unique_counts <- data.frame(
  Dataset = c("train", "test", "bureau", "previous_application", "installments_payments", "credit_card_balance"),
  Unique_SK_ID_CURR = c(length(unique(train$SK_ID_CURR)), 
                         length(unique(test$SK_ID_CURR)), 
                         length(unique(bureau$SK_ID_CURR)), 
                         length(unique(previous_application$SK_ID_CURR)), 
                         length(unique(installments_payments$SK_ID_CURR)), 
                         length(unique(credit_card_balance$SK_ID_CURR)))
)
print(unique_counts)
```
## Explore Target Variable
```{r message=FALSE, warning=FALSE}
target_distribution <- table(train$TARGET)
print(target_distribution)
```

```{r message=FALSE, warning=FALSE}
# Calculate percentages
target_percent <- train %>%
  count(TARGET) %>%
  mutate(Percent = n / sum(n) * 100,
         TARGET = factor(TARGET, labels = c("Repaid", "Defaulted")))

# Plot
ggplot(target_percent, aes(x = TARGET, y = Percent)) +
  geom_bar(stat = "identity", fill = "steelblue4") +
  geom_text(aes(label = paste0(round(Percent, 1), "%")), 
            vjust = -0.5, size = 6) +  # larger label size
  labs(title = "Loan Repayment vs. Default (as % of Total)",
       x = "Loan Status",
       y = "Percentage (%)") +
  theme_minimal(base_size = 16) +  # larger base font
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.title = element_text(size = 18),
    plot.title = element_text(size = 20, face = "bold", hjust = 0.5)
  )

```

The dataset is imbalanced, with large repaid loans and small defaults. This means the model might focus too much on repaid loans and miss high-risk applicants. If not handled, it could lead to more loan defaults and financial losses. To fix this, techniques like oversampling or adjusting model training might applied.


# Discussion of Missing Data

## Check Misssing Value
```{r message=FALSE, warning=FALSE}
missing_values <- function(df) {
  missings <- colSums(is.na(df)) / nrow(df) * 100
  return(data.frame(Column = names(missings), Missing_Percentage = missings))
}

missing_summary <- list(
  train = missing_values(train),
  test = missing_values(test),
  bureau = missing_values(bureau),
  bureau_balance = missing_values(bureau_balance),
  previous_application = missing_values(previous_application),
  installments_payments = missing_values(installments_payments),
  credit_card_balance = missing_values(credit_card_balance)
)

# display 
for (name in names(missing_summary)) {
  cat("\nMissing values in", name, ":\n")
  print(missing_summary[[name]] %>% filter(Missing_Percentage > 0) %>% arrange(desc(Missing_Percentage)))
}
```

## Remove Columns with Too Many Missing Values
```{r message=FALSE, warning=FALSE}
# Function to remove columns with high missing percentage
remove_high_missing <- function(df, threshold = 50) {
  missing_perc <- colSums(is.na(df)) / nrow(df) * 100
  cols_to_keep <- names(missing_perc[missing_perc < threshold])
  return(df[, cols_to_keep])
}


train <- remove_high_missing(train)
test <- remove_high_missing(test)
bureau <- remove_high_missing(bureau)
previous_application <- remove_high_missing(previous_application)
credit_card_balance <- remove_high_missing(credit_card_balance)
POS_CASH_balance <- remove_high_missing(POS_CASH_balance)
installments_payments <- remove_high_missing(installments_payments)
```

## Fill Numeric Columns with Mean/Median
```{r message=FALSE, warning=FALSE}
# Function to fill missing values with median
fill_missing_numeric <- function(df) {
  for (col in colnames(df)) {
    if (is.numeric(df[[col]])) {
      df[[col]][is.na(df[[col]])] <- median(df[[col]], na.rm = TRUE)
    }
  }
  return(df)
}

train <- fill_missing_numeric(train)
test <- fill_missing_numeric(test)
bureau <- fill_missing_numeric(bureau)
previous_application <- fill_missing_numeric(previous_application)
credit_card_balance <- fill_missing_numeric(credit_card_balance)
POS_CASH_balance <- fill_missing_numeric(POS_CASH_balance)
installments_payments <- fill_missing_numeric(installments_payments)
```

## Fill Categorical Columns with Most Frequent Value
```{r message=FALSE, warning=FALSE}
# Function to fill missing categorical values with the most frequent category
fill_missing_categorical <- function(df) {
  for (col in colnames(df)) {
    if (is.character(df[[col]])) {
      most_frequent <- names(sort(table(df[[col]]), decreasing = TRUE))[1]
      df[[col]][is.na(df[[col]])] <- most_frequent
    }
  }
  return(df)
}


train <- fill_missing_categorical(train)
test <- fill_missing_categorical(test)
previous_application <- fill_missing_categorical(previous_application)
```

## No Missing Values Left
```{r message=FALSE, warning=FALSE}
check_missing <- function(df, name) {
  missing_count <- sum(is.na(df))
  cat(name, "- Remaining Missing Values:", missing_count, "\n")
}

check_missing(train, "train")
check_missing(test, "test")
check_missing(bureau, "bureau")
check_missing(previous_application, "previous_application")
check_missing(credit_card_balance, "credit_card_balance")
check_missing(POS_CASH_balance, "POS_CASH_balance")
check_missing(installments_payments, "installments_payments")
```

# Data Coverting

## Convert variables to factors
```{r message=FALSE, warning=FALSE}
# Convert character variables to factors before merging (to save memory)
train <- train %>% mutate_if(is.character, as.factor)
test <- test %>% mutate_if(is.character, as.factor)
bureau <- bureau %>% mutate_if(is.character, as.factor)
bureau_balance <- bureau_balance %>% mutate_if(is.character, as.factor)
previous_application <- previous_application %>% mutate_if(is.character, as.factor)
POS_CASH_balance <- POS_CASH_balance %>% mutate_if(is.character, as.factor)
installments_payments <- installments_payments %>% mutate_if(is.character, as.factor)
credit_card_balance <- credit_card_balance %>% mutate_if(is.character, as.factor)
```

# Exploratory Visualizations and Summary Tables

## Visualize Differences in Income & Loan Amount
```{r message=FALSE, warning=FALSE}
ggplot(train, aes(x = as.factor(TARGET), y = AMT_INCOME_TOTAL)) +
  geom_boxplot(fill = "indianred4", outlier.shape = NA) +
  scale_y_continuous(limits = quantile(train$AMT_INCOME_TOTAL, c(0.01, 0.99), na.rm = TRUE)) + 
  labs(title = "Income Distribution by Loan Repayment", x = "TARGET (0 = Repaid, 1 = Defaulted)", y = "Income") +
  theme_minimal()
```

```{r message=FALSE, warning=FALSE}
ggplot(train, aes(x = as.factor(TARGET), y = AMT_CREDIT)) +
  geom_boxplot(fill = "indianred4", outlier.shape = NA) +
  scale_y_continuous(limits = quantile(train$AMT_CREDIT, c(0.01, 0.99), na.rm = TRUE)) + 
  labs(title = "Loan Amount Distribution by Loan Repayment", x = "TARGET (0 = Repaid, 1 = Defaulted)", y = "Loan Amount") +
  theme_minimal()
```
The boxplots show that income and loan amount distributions are very similar for both repaid and defaulted loans. While defaulted applicants tend to have a slightly lower median income, there are large outliers, indicating that some applicants have very high incomes. Similarly, loan amounts for both groups show a wide range, with defaulted applicants having a slightly lower median loan amount. However, these differences are not significant, suggesting that income alone is not a strong predictor of loan repayment. To better understand default risks, we need to analyze other financial behaviors like past credit history and payment patterns.

## Financial Behavior Analysis
- **Check how many applicants had previous loans from other financial institutions.**
- **Calculate the average number of past credits per applicant.**
```{r message=FALSE, warning=FALSE}
# Count applicants with previous loans
applicants_with_external_loans <- bureau %>%
  group_by(SK_ID_CURR) %>%
  summarise(num_past_loans = n()) %>%
  filter(num_past_loans > 0)

# Number of applicants with external loans
num_applicants_with_loans <- n_distinct(applicants_with_external_loans$SK_ID_CURR)
cat("Number of applicants with previous external loans:", num_applicants_with_loans, "\n")

# Average number of past credits per applicant
avg_past_credits <- mean(applicants_with_external_loans$num_past_loans)
cat("Average number of past credits per applicant:", avg_past_credits, "\n")
```

## Analyzing Payment Behavior
```{r message=FALSE, warning=FALSE}
# Late or missed payments in credit card balance
late_credit_payments <- credit_card_balance %>%
  filter(AMT_PAYMENT_CURRENT < AMT_INST_MIN_REGULARITY) %>%
  group_by(SK_ID_CURR) %>%
  summarise(num_late_payments = n())

# Late or missed payments in installments
late_installments <- installments_payments %>%
  filter(DAYS_ENTRY_PAYMENT > DAYS_INSTALMENT) %>%
  group_by(SK_ID_CURR) %>%
  summarise(num_late_installments = n())

# POS_CASH_balance - Count overdue payments
overdue_POS <- POS_CASH_balance %>%
  filter(SK_DPD > 0) %>%
  group_by(SK_ID_CURR) %>%
  summarise(num_overdue_POS = n())

# Avg missed payments per applicant
avg_late_credit <- mean(late_credit_payments$num_late_payments, na.rm = TRUE)
avg_late_installments <- mean(late_installments$num_late_installments, na.rm = TRUE)
avg_overdue_POS <- mean(overdue_POS$num_overdue_POS, na.rm = TRUE)

cat("Average number of late credit card payments:", avg_late_credit, "\n")
cat("Average number of late installment payments:", avg_late_installments, "\n")
cat("Average number of overdue POS payments:", avg_overdue_POS, "\n")

```


# Feature Engineering: Aggregating Financial Data
```{r message=FALSE, warning=FALSE}
# Aggregate secondary datasets to ensure one row per SK_ID_CURR
bureau_agg <- bureau %>%
  group_by(SK_ID_CURR) %>%
  summarise(TOTAL_CREDIT_ACTIVE = n(),
            MAX_CREDIT_OVERDUE = max(CREDIT_DAY_OVERDUE, na.rm=TRUE))

previous_application_agg <- previous_application %>%
  group_by(SK_ID_CURR) %>%
  summarise(TOTAL_PREVIOUS_APPLICATIONS = n(),
            AVERAGE_AMT_CREDIT = mean(AMT_CREDIT, na.rm=TRUE))

POS_CASH_balance_agg <- POS_CASH_balance %>%
  group_by(SK_ID_CURR) %>%
  summarise(AVERAGE_MONTHS_BALANCE = mean(MONTHS_BALANCE, na.rm=TRUE))

credit_card_balance_agg <- credit_card_balance %>%
  group_by(SK_ID_CURR) %>%
  summarise(AVERAGE_AMT_BALANCE = mean(AMT_BALANCE, na.rm=TRUE))

installments_payments_agg <- installments_payments %>%
  group_by(SK_ID_CURR) %>%
  summarise(AVERAGE_DAYS_INSTALMENT = mean(DAYS_INSTALMENT, na.rm=TRUE))

```


## Merge into Main Train Data
```{r message=FALSE, warning=FALSE}
# Merge datasets
merged_train <- train %>%
  left_join(bureau_agg, by = "SK_ID_CURR") %>%
  left_join(previous_application_agg, by = "SK_ID_CURR") %>%
  left_join(POS_CASH_balance_agg, by = "SK_ID_CURR") %>%
  left_join(credit_card_balance_agg, by = "SK_ID_CURR") %>%
  left_join(installments_payments_agg, by = "SK_ID_CURR")

```

## Merge into Main Test Data
```{r message=FALSE, warning=FALSE}
# Merge test dataset separately for prediction
merged_test <- test %>%
  left_join(bureau_agg, by = "SK_ID_CURR") %>%
  left_join(previous_application_agg, by = "SK_ID_CURR") %>%
  left_join(POS_CASH_balance_agg, by = "SK_ID_CURR") %>%
  left_join(credit_card_balance_agg, by = "SK_ID_CURR") %>%
  left_join(installments_payments_agg, by = "SK_ID_CURR")
```

## Display Merged
```{r message=FALSE, warning=FALSE}
# Display dataset
cat("Train Data: ", dim(merged_train), "\n")
cat("Test Data: ", dim(merged_test), "\n")
```

# Final Data Wrangling

## Check Missing Values in Final Merged Datasets
```{r message=FALSE, warning=FALSE}
# Function to check missing values in a dataset
check_missing <- function(df, name) {
  missing_count <- sum(is.na(df))
  missing_percentage <- (missing_count / (nrow(df) * ncol(df))) * 100
  cat(name, "- Total Missing Values:", missing_count, 
      "| Percentage of Missing Values:", round(missing_percentage, 2), "%\n")
}

# Check missing values in merged train and test datasets
check_missing(merged_train, "Merged Train Data")
check_missing(merged_test, "Merged Test Data")

# Show columns with missing values in merged_train
missing_train_summary <- colSums(is.na(merged_train)) / nrow(merged_train) * 100
missing_train_summary <- missing_train_summary[missing_train_summary > 0]
if (length(missing_train_summary) > 0) {
  cat("\nColumns with Missing Values in Merged Train Data:\n")
  print(missing_train_summary)
}

# Show columns with missing values in merged_test
missing_test_summary <- colSums(is.na(merged_test)) / nrow(merged_test) * 100
missing_test_summary <- missing_test_summary[missing_test_summary > 0]
if (length(missing_test_summary) > 0) {
  cat("\nColumns with Missing Values in Merged Test Data:\n")
  print(missing_test_summary)
}

```
## Replace Nas By Zero
```{r message=FALSE, warning=FALSE}
# Function to fill missing values in merged datasets
fill_missing_values <- function(df) {
  df$TOTAL_CREDIT_ACTIVE[is.na(df$TOTAL_CREDIT_ACTIVE)] <- 0
  df$MAX_CREDIT_OVERDUE[is.na(df$MAX_CREDIT_OVERDUE)] <- 0
  df$TOTAL_PREVIOUS_APPLICATIONS[is.na(df$TOTAL_PREVIOUS_APPLICATIONS)] <- 0
  df$AVERAGE_AMT_CREDIT[is.na(df$AVERAGE_AMT_CREDIT)] <- 0
  df$AVERAGE_MONTHS_BALANCE[is.na(df$AVERAGE_MONTHS_BALANCE)] <- 0
  df$AVERAGE_AMT_BALANCE[is.na(df$AVERAGE_AMT_BALANCE)] <- 0
  df$AVERAGE_DAYS_INSTALMENT[is.na(df$AVERAGE_DAYS_INSTALMENT)] <- 0
  return(df)
}

# Apply missing value handling to both datasets
merged_train <- fill_missing_values(merged_train)
merged_test <- fill_missing_values(merged_test)
```

## Verify no missing values remain
```{r message=FALSE, warning=FALSE}
check_missing(merged_train, "Merged Train Data (After Fixing)")
check_missing(merged_test, "Merged Test Data (After Fixing)")
```


# Correlation Analysis
## Correlation Table
```{r message=FALSE, warning=FALSE}
merged_train$TARGET <- as.factor(merged_train$TARGET)

numeric_columns <- merged_train %>%
  select(where(is.numeric))

# Compute Point Biserial Correlation for each numeric variable with TARGET
cor_results <- sapply(numeric_columns, function(x) {
  cor.test(x, as.numeric(merged_train$TARGET), method = "pearson")$estimate
})

# Sort correlations by absolute value
cor_results_sorted <- sort(abs(cor_results), decreasing = TRUE)

# Display results
print(cor_results_sorted)
```
## Top 10 Correlation Variables
```{r}
# Convert correlation results to data frame
cor_df <- data.frame(Feature = names(cor_results_sorted), Correlation = cor_results_sorted)

# Select top 10 correlated features (adjust if less than 10 exist)
top_features <- cor_df[1:min(10, nrow(cor_df)), ]


ggplot(top_features, aes(x = reorder(Feature, Correlation), y = Correlation)) +
  geom_bar(stat = "identity", fill = "indianred4") +
  coord_flip() +
  labs(title = "Top 10 Features Correlated with TARGET", x = "Feature", y = "Correlation Score") +
  theme_minimal()
```

# Results Section

The analysis found a significant class imbalance in the dataset, with 91.9% of applicants repaying loans and only 8.1% defaulting. This imbalance may affect model performance and requires techniques to ensure fair predictions.

The financial behavior analysis showed that many applicants had previous loans, and those who defaulted often had multiple past loans with late or missed payments. Credit utilization and overdue payments were more common among defaulters, suggesting these factors may indicate higher risk.

In the correlation analysis, late payment ratio and average overdue days showed a positive correlation with default risk, meaning higher values increase the chance of default. Approval rate had a negative correlation, suggesting that applicants with more past loan approvals were less likely to default. Income, loan amount, and credit utilization had weak or no correlation, making them poor predictors of repayment behavior.

To improve model performance, I would like to fucus more on late payment ratio, overdue days, and approval rate, while removing weak features like income, loan amount, and credit utilization. The next step is to apply feature importance analysis using predictive models to refine feature selection and enhance prediction accuracy.

# Export Finial Merged Data for Models
```{r message=FALSE, warning=FALSE}
# Save merged datasets for modeling
write.csv(merged_train, "merged_train.csv", row.names = FALSE)
write.csv(merged_test, "merged_test.csv", row.names = FALSE)
```
